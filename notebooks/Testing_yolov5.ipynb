{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3ee719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from IPython.display import Image, clear_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55c51134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=../yolov5/data/coco128.yaml, hyp=../yolov5/data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=16, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=../yolov5/runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
      "YOLOv5 üöÄ 2022-10-15 Python-3.8.12 torch-1.12.1 CPU\n",
      "\n",
      "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
      "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 üöÄ in ClearML\n",
      "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 üöÄ runs in Comet\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir ../yolov5/runs/train', view at http://localhost:6006/\n",
      "\n",
      "Dataset not found ‚ö†Ô∏è, missing paths ['/Users/bita/code/danielcerdae/smart-reader/datasets/coco128/images/train2017']\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.66M/6.66M [00:00<00:00, 12.9MB/s]\n",
      "Dataset download success ‚úÖ (4.0s), saved to \u001b[1m/Users/bita/code/danielcerdae/smart-reader/datasets\u001b[0m\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
      "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1    229245  models.yolo.Detect                      [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model summary: 214 layers, 7235389 parameters, 7235389 gradients, 16.6 GFLOPs\n",
      "\n",
      "Transferred 349/349 items from yolov5s.pt\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/Users/bita/code/danielcerdae/smart-reader/datasets/coco128/lab\u001b[0m\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /Users/bita/code/danielcerdae/smart-reader/datasets/coco128/labels/train2017.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning '/Users/bita/code/danielcerdae/smart-reader/datasets/coco128/label\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.27 anchors/target, 0.994 Best Possible Recall (BPR). Current anchors are a good fit to dataset ‚úÖ\n",
      "Plotting labels to ../yolov5/runs/train/exp12/labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m../yolov5/runs/train/exp12\u001b[0m\n",
      "Starting training for 5 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        0/4         0G    0.04436    0.05841     0.0173        164        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.656      0.603      0.677      0.448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        1/4         0G    0.04512    0.06339    0.01566        185        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.726       0.62      0.722      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        2/4         0G    0.04326    0.06372    0.01553        182        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929       0.78      0.641       0.75      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        3/4         0G    0.04501    0.05915    0.01573        248        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929       0.79      0.657      0.759      0.508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
      "        4/4         0G    0.04444    0.06366    0.01508        219        640: 1\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.832      0.648       0.77      0.516\n",
      "\n",
      "5 epochs completed in 0.299 hours.\n",
      "Optimizer stripped from ../yolov5/runs/train/exp12/weights/last.pt, 14.9MB\n",
      "Optimizer stripped from ../yolov5/runs/train/exp12/weights/best.pt, 14.9MB\n",
      "\n",
      "Validating ../yolov5/runs/train/exp12/weights/best.pt...\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all        128        929      0.832      0.647       0.77      0.515\n",
      "                person        128        254      0.901      0.679      0.812      0.538\n",
      "               bicycle        128          6      0.869        0.5       0.78      0.471\n",
      "                   car        128         46      0.767      0.435      0.556      0.245\n",
      "            motorcycle        128          5      0.836        0.8      0.872      0.679\n",
      "              airplane        128          6      0.989          1      0.995      0.679\n",
      "                   bus        128          7      0.888      0.714       0.78       0.67\n",
      "                 train        128          3          1      0.578      0.995      0.537\n",
      "                 truck        128         12      0.781        0.5      0.591      0.334\n",
      "                  boat        128          6          1      0.323       0.67      0.292\n",
      "         traffic light        128         14      0.927      0.214      0.404      0.223\n",
      "             stop sign        128          2      0.804          1      0.995      0.821\n",
      "                 bench        128          9      0.836      0.567      0.742      0.338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  bird        128         16       0.96          1      0.995      0.681\n",
      "                   cat        128          4      0.913          1      0.995      0.772\n",
      "                   dog        128          9          1      0.654      0.984      0.754\n",
      "                 horse        128          2       0.89          1      0.995      0.597\n",
      "              elephant        128         17      0.977      0.882      0.939      0.715\n",
      "                  bear        128          1      0.721          1      0.995      0.995\n",
      "                 zebra        128          4       0.86          1      0.995      0.905\n",
      "               giraffe        128          9      0.779      0.782      0.932      0.707\n",
      "              backpack        128          6      0.996        0.5      0.739      0.322\n",
      "              umbrella        128         18      0.839      0.722      0.892      0.513\n",
      "               handbag        128         19          1      0.234      0.393      0.203\n",
      "                   tie        128          7      0.828       0.69      0.752      0.478\n",
      "              suitcase        128          4      0.885          1      0.995      0.558\n",
      "               frisbee        128          5      0.734        0.8        0.8      0.716\n",
      "                  skis        128          1      0.846          1      0.995        0.3\n",
      "             snowboard        128          7      0.895      0.714      0.846      0.534\n",
      "           sports ball        128          6      0.697      0.667      0.602      0.353\n",
      "                  kite        128         10      0.856        0.6      0.641      0.242\n",
      "          baseball bat        128          4      0.945        0.5      0.544      0.274\n",
      "        baseball glove        128          7       0.75      0.429       0.47      0.309\n",
      "            skateboard        128          5      0.745        0.6      0.739       0.51\n",
      "         tennis racket        128          7       0.81      0.429      0.549      0.319\n",
      "                bottle        128         18      0.622      0.367      0.596      0.286\n",
      "            wine glass        128         16       0.76      0.875      0.914      0.494\n",
      "                   cup        128         36       0.86      0.684      0.829      0.524\n",
      "                  fork        128          6          1      0.316      0.516      0.333\n",
      "                 knife        128         16      0.655      0.596      0.704      0.413\n",
      "                 spoon        128         22      0.906      0.439      0.657      0.401\n",
      "                  bowl        128         28      0.894      0.607      0.743       0.54\n",
      "                banana        128          1      0.865          1      0.995      0.305\n",
      "              sandwich        128          2          1          0      0.745      0.671\n",
      "                orange        128          4      0.901          1      0.995      0.672\n",
      "              broccoli        128         11      0.723      0.364      0.497      0.368\n",
      "                carrot        128         24       0.69      0.558      0.724      0.492\n",
      "               hot dog        128          2      0.557          1      0.995       0.92\n",
      "                 pizza        128          5      0.877        0.8      0.962      0.751\n",
      "                 donut        128         14      0.646          1      0.946      0.792\n",
      "                  cake        128          4      0.853          1      0.995      0.809\n",
      "                 chair        128         35      0.578        0.6      0.638      0.354\n",
      "                 couch        128          6       0.93      0.667      0.843      0.549\n",
      "          potted plant        128         14      0.845      0.778      0.848      0.511\n",
      "                   bed        128          3          1          0      0.731      0.459\n",
      "          dining table        128         13       0.79      0.293      0.575      0.334\n",
      "                toilet        128          2      0.937          1      0.995      0.846\n",
      "                    tv        128          2      0.686          1      0.995      0.846\n",
      "                laptop        128          3          1          0      0.764      0.426\n",
      "                 mouse        128          2          1          0      0.107     0.0536\n",
      "                remote        128          8          1       0.62      0.636      0.564\n",
      "            cell phone        128          8      0.797      0.492      0.469      0.295\n",
      "             microwave        128          3      0.813          1      0.995      0.766\n",
      "                  oven        128          5      0.425        0.4      0.454       0.32\n",
      "                  sink        128          6      0.568      0.333      0.401      0.281\n",
      "          refrigerator        128          5      0.648        0.8      0.811      0.547\n",
      "                  book        128         29       0.68      0.293      0.378       0.18\n",
      "                 clock        128          9      0.859      0.889       0.94      0.743\n",
      "                  vase        128          2      0.524          1      0.995      0.945\n",
      "              scissors        128          1          1          0      0.497     0.0498\n",
      "            teddy bear        128         21      0.871      0.667      0.822      0.555\n",
      "            toothbrush        128          5      0.822          1      0.995      0.606\n",
      "Results saved to \u001b[1m../yolov5/runs/train/exp12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train YOLOv5s on COCO128 for 5 epochs\n",
    "!python ../yolov5/train.py --img 640 --batch 16 --epochs 5 --data ../yolov5/data/coco128.yaml --weights yolov5s.pt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310ef27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
